---
permalink: /
title: 
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a rising fifth-year PhD student in Decision Sciences at INSEAD. I am immensely fortunate to be advised by [Hamsa Bastani](https://hamsabastani.github.io/index.html) and [Spyros Zoumpoulis](https://www.insead.edu/faculty-personal-site/spyros-zoumpoulis/research).


My research agenda centers on a key question: <em>how should we design algorithms and govern their use to maximize productivity and develop human capital?</em>
This question guides my research in behavioral, service, and AI-driven operations. I study <em>human-AI systems</em> by integrating sequential decision-making modeling with behavioral experiments and industry collaborations to enrich both theory and managerial practice. My research shows that even reliable algorithms and accurate AI recommendations can undermine performance and hinder human learning.

Prior to my PhD, I embarked on an entrepreneurial journey, earning recognition on the Forbes 30 Under 30 list for Greece. I also contributed to womenâ€™s economic development through my public policy and education roles at MExoxo. 

I hold a B.S. and M.S. in Electrical and Computer Engineering from the National Technical University of Athens. 

<p>
  <a href="/files/Stefanos_Poulidis_CV.pdf" 
     style="display:inline-block; padding:4px 10px; font-size:90%; background:#1a73e8; color:#fff; border-radius:4px; text-decoration:none; font-weight:bold;">
    ðŸ“„ View my CV
  </a>
</p>


**Research interests**

behavioral operations, human-AI collaboration, AI governance, service operations, human capital development

## Research

  <h3><strong>Action vs. Attention Signals for Human-AI Collaboration: Evidence from Chess</strong></h3> 
  with Haosen Ge, Hamsa Bastani, and Osbert Bastani  

   <em>Major Revision</em>, **Management Science**

  <ul class="pub-awards">
    <li><em>1st Place</em>, Decision Analysis Society Student Paper Award, 2025</li>
    <li><em>Finalist</em>, TIMES Best Working Paper Award, 2025</li>
  </ul>
   
  <button onclick="toggleAbstract('abstract1')" class="pub-btn">Abstract</button> 
  <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5128584" target="_blank" class="pub-btn">Working Paper</a>

  <div id="abstract1" class="pub-abstract">
    <p>Algorithmic advice increasingly supports human decision-making in high-stakes domains such as healthcare, law, and finance. While prior work has mostly studied <i>action signals</i>, which recommend specific actions, many practical implementations actually rely on <i>attention signals</i>, which highlight critical decisions without prescribing a course of actionâ€”e.g., in hospitals, attention signals may trigger upon encountering high-risk patients, while action signals may additionally suggest specific treatments for those patients. NaÃ¯vely, if both kinds of signals are reliable, then action signals may be clearly preferable since they provide significantly more information to the decision-maker. To assess this hypothesis, we study the impact of these signals on human decision-making via an extensive behavioral experiment in the context of chess, a challenging and well-studied decision-making problem where experts frequently rely on algorithmic advice. We find that both signal types can effectively improve decision-making, with attention signals achieving at least 40% of the benefits of action signals. However, we find that action signals only improve decision-making in the specific states where they are provided, and can even guide decision-makers into "uncharted waters" where they are unsure how to make effective decisions, thereby degrading subsequent performance. In contrast, attention signals improve decision-making quality not only in states where they are given, but also in subsequent states. Our findings suggest that action signals act as substitutes for human thinking, whereas attention signals act as complementsâ€”thus, attention signals may be preferable to action signals even in settings where both kinds of signals are considered reliable.</p>
  </div>




  <h3><strong>Self-Regulated AI Use Hinders Long-Term Learning</strong></h3> 
  with Hamsa Bastani and Osbert Bastani

  <button onclick="toggleAbstract('abstract1')" class="pub-btn">Abstract</button> 
  <a href="https://www.dropbox.com/scl/fi/xr01rbd9kiui5nbj7ta17/Self-Regulated-AI-Use-Hinders-Long-Term-Learning.pdf?rlkey=iw9o87ngri1q2vrfdsh3ricec&st=ehfvwnhy&dl=0" target="_blank" class="pub-btn">Working Paper</a>

  <div id="abstract1" class="pub-abstract">
    <p>There has been significant recent interest in leveraging artificial intelligence (AI) tutors to aid student learning. Current systems enable students to control the timing and nature of AI assistance; however, this student-directed access risks short-circuiting the effortful practice essential for lasting expertise. To understand these risks, we conducted a long-term field experiment with over 200 chess club students training on a custom AI-assisted chess platform. Students were randomly assigned to either a <i>system-regulated</i> condition, where the platform automatically provided AI tips at key moments, or a <i>self-regulated</i> condition, where students could additionally request help at any time by clicking a button. After 12 weeks of training, we find that both groups improved their chess skills, but students in the self-regulated condition achieved less than half the performance gains of students in the system-regulated condition (30% vs. 64%). We identify two potential mechanisms for these adverse effects: reduced engagement and diminished productive struggleâ€”students in the self-regulated condition trained less, reported a lower sense of accomplishment, and became increasingly reliant on AI even though they were aware of its harms. We also show that these effects are mitigated among highly motivated students, but not among highly skilled students. Our findings demonstrate that while scaffolded AI assistance can accelerate learning, unrestricted access can undermine it.</p>
  </div>



  <h3><strong>Generative AI Workflows at Work</strong></h3> 
  with Hamsa Bastani and Spyros Zoumpoulis 


   <h3><strong>To Alert or to Tell? Optimizing AI Signals for Decision-Making</strong></h3>


## Fieldwork

<!-- Carousel Container -->
<div class="fieldwork-carousel">
  <div class="swiper-container">
    <div class="swiper-wrapper">
      <div class="swiper-slide">
        <img src="{{ site.baseurl }}/assets/images/FIDE_post.png" alt="FIDE post">
        <p class="swiper-caption">FIDE officially communicates our study!</p>
      </div>
      <div class="swiper-slide">
        <img src="{{ site.baseurl }}/assets/images/chess_kids.jpg" alt="Chesskids">
        <p class="swiper-caption">Presenting our chess-training platform to chess academies</p>
      </div>
      <div class="swiper-slide">
        <img src="{{ site.baseurl }}/assets/images/chess_academies_3.jpeg" alt="Chess Academies Visit">
        <p class="swiper-caption">Wrapping up the study with chess-themed stickers!</p>
      </div>
      <div class="swiper-slide">
        <img src="{{ site.baseurl }}/assets/images/chessed.png" alt="Chessineducation">
        <p class="swiper-caption">Our chess-training study featured in the Chess-in-Education newsletter</p>
      </div>
    </div>
    <!-- Pagination & Navigation Buttons -->
    <div class="swiper-pagination"></div>
  </div>
</div>


---
